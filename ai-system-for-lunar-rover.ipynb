{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install segmentation_models","metadata":{"id":"HRJUKjN1QXgS","execution":{"iopub.status.busy":"2022-02-17T17:10:00.912166Z","iopub.execute_input":"2022-02-17T17:10:00.912461Z","iopub.status.idle":"2022-02-17T17:10:11.294354Z","shell.execute_reply.started":"2022-02-17T17:10:00.912373Z","shell.execute_reply":"2022-02-17T17:10:11.293589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nimport segmentation_models as sm\nimport glob\nimport cv2\nimport os\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport keras \nfrom sklearn.model_selection import train_test_split","metadata":{"id":"bGIcq3_DQXgT","execution":{"iopub.status.busy":"2022-02-17T17:10:25.360792Z","iopub.execute_input":"2022-02-17T17:10:25.361492Z","iopub.status.idle":"2022-02-17T17:10:31.240084Z","shell.execute_reply.started":"2022-02-17T17:10:25.361446Z","shell.execute_reply":"2022-02-17T17:10:31.239373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Provide environment variable SM_FRAMEWORK=keras / SM_FRAMEWORK=tf.keras before import segmentation_models\n* Change framework sm.set_framework('keras') / sm.set_framework('tf.keras')","metadata":{"id":"TIJMgWvKm8y7"}},{"cell_type":"code","source":"os.environ[\"SM_FRAMEWORK\"] = \"tf.keras\"\nsm.set_framework('tf.keras')\nkeras.backend.set_image_data_format('channels_last')","metadata":{"id":"x2HKIVofm8y7","execution":{"iopub.status.busy":"2022-02-17T17:10:35.708969Z","iopub.execute_input":"2022-02-17T17:10:35.709464Z","iopub.status.idle":"2022-02-17T17:10:36.012546Z","shell.execute_reply.started":"2022-02-17T17:10:35.709426Z","shell.execute_reply":"2022-02-17T17:10:36.0118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Preprocessing Pipeline","metadata":{"id":"OdS9NTtwQXgV"}},{"cell_type":"code","source":"H = 256 # height of image\nW = 256 # width of image\n\n'''This function is used to return the list of path for images and masks in\nsorted order from the given directory respectively.'''\n# function to return list of image paths and mask paths \ndef process_data(IMG_DIR, MASK_DIR):\n    images = [os.path.join(IMG_DIR, x) for x in sorted(os.listdir(IMG_DIR))]\n    masks = [os.path.join(MASK_DIR, x) for x in sorted(os.listdir(MASK_DIR))]\n\n    return images, masks\n\n'''This function is used to return splitted list of images and corresponding \nmask paths in train and test by providing test size.'''\n# function to load data and train test split\ndef load_data(IMG_DIR, MASK_DIR):\n    X, y = process_data(IMG_DIR, MASK_DIR)\n    \n    X_train, X_test, y_train, y_test = train_test_split(\n        X, y, test_size=0.2, random_state=42)\n    \n    return X_train, X_test, y_train, y_test\n\n'''This function is used to read images. It takes image path as input. \nAfter reading image it is resized by width and height provide above(256 x 256). \nNext normalization is done by dividing each values with 255. And the result is returned.'''\n# function to read image\ndef read_image(x):\n    x = cv2.imread(x, cv2.IMREAD_COLOR)\n    x = cv2.resize(x, (W, H))\n    x = x / 255.0\n    x = x.astype(np.float32)\n    return x\n\n'''This function is used to read masks.'''\n# function to read mask\ndef read_mask(x):\n    x = cv2.imread(x, cv2.IMREAD_GRAYSCALE)\n    x = cv2.resize(x, (W, H))\n    x = x.astype(np.int32)\n    return x\n\n'''This function is used to generate tensorflow data pipeline. \nThe tensorflow data pipeline is mapped to function ‘preprocess’ .'''\n# function for tensorflow dataset pipeline\ndef tf_dataset(x, y, batch=8):\n    dataset = tf.data.Dataset.from_tensor_slices((x, y))\n    dataset = dataset.shuffle(buffer_size=5000)\n    dataset = dataset.map(preprocess)\n    dataset = dataset.batch(batch)\n    dataset = dataset.repeat()\n    dataset = dataset.prefetch(2)\n    return dataset\n\n'''This function takes image and mask path. \nIt reads the image and mask as provided by paths. \nMask is one hot encoded for multi class segmentation (here 4 class).'''\n# function to read image and mask amd create one hot encoding for mask\ndef preprocess(x, y):\n    def f(x, y):\n        x = x.decode()\n        y = y.decode()\n\n        image = read_image(x)\n        mask = read_mask(y)\n\n        return image, mask\n\n    image, mask = tf.numpy_function(f, [x, y], [tf.float32, tf.int32])\n    mask = tf.one_hot(mask, 4, dtype=tf.int32)\n    image.set_shape([H, W, 3])\n    mask.set_shape([H, W, 4])\n\n    return image, mask","metadata":{"id":"EQGsLbOVQXgW","execution":{"iopub.status.busy":"2022-02-17T17:10:43.821401Z","iopub.execute_input":"2022-02-17T17:10:43.821689Z","iopub.status.idle":"2022-02-17T17:10:43.836056Z","shell.execute_reply.started":"2022-02-17T17:10:43.821656Z","shell.execute_reply":"2022-02-17T17:10:43.834824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load the dataset","metadata":{"id":"ufOlyg7MQXgY"}},{"cell_type":"code","source":"'''RENDER_IMAGE_DIR_PATH: ‘Path of image directory’\nGROUND_MASK_DIR_PATH: ‘Path of mask directory’\n\nHere load_data function is called. This will load the dataset paths and \nsplit it into X_train, X_test, y_train, y_test '''\n\nRENDER_IMAGE_DIR_PATH = '../input/artificial-lunar-rocky-landscape-dataset/images/render'\nGROUND_MASK_DIR_PATH = '../input/artificial-lunar-rocky-landscape-dataset/images/clean'\n\nX_train, X_test, y_train, y_test = load_data(RENDER_IMAGE_DIR_PATH, GROUND_MASK_DIR_PATH)\nprint(f\"Dataset:\\n Train: {len(X_train)} \\n Test: {len(X_test)}\")","metadata":{"id":"vHWstFNTQXgY","execution":{"iopub.status.busy":"2022-02-17T17:10:53.501194Z","iopub.execute_input":"2022-02-17T17:10:53.50145Z","iopub.status.idle":"2022-02-17T17:10:54.599429Z","shell.execute_reply.started":"2022-02-17T17:10:53.50142Z","shell.execute_reply":"2022-02-17T17:10:54.598694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Generate tensorflow data pipeline","metadata":{"id":"WfSTVsjCQXgZ"}},{"cell_type":"code","source":"batch_size = 8\n\n'''Here the tf_dataset function is called will generate the tensorflow data pipeline.'''\n# calling tf_dataset\ntrain_dataset = tf_dataset(X_train, y_train, batch=batch_size)\nvalid_dataset = tf_dataset(X_test, y_test, batch=batch_size)","metadata":{"id":"4xsJKtW0QXgZ","execution":{"iopub.status.busy":"2022-02-17T17:11:10.474324Z","iopub.execute_input":"2022-02-17T17:11:10.474919Z","iopub.status.idle":"2022-02-17T17:11:10.563435Z","shell.execute_reply.started":"2022-02-17T17:11:10.474876Z","shell.execute_reply":"2022-02-17T17:11:10.562797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Creating U-net Architecture","metadata":{"id":"1MqxtDTmQXga"}},{"cell_type":"code","source":"from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Activation, MaxPool2D, UpSampling2D, Concatenate\nfrom tensorflow.keras.models import Model\n\n'''conv_block it is used to create one block with two convolution layer \nfollowed by BatchNormalization and activation function relu. \nIf the pooling is required then Maxpool2D is applied and return it else not.'''\n# function to create convolution block\ndef conv_block(inputs, filters, pool=True):\n    x = Conv2D(filters, 3, padding=\"same\")(inputs)\n    x = BatchNormalization()(x)\n    x = Activation(\"relu\")(x)\n\n    x = Conv2D(filters, 3, padding=\"same\")(x)\n    x = BatchNormalization()(x)\n    x = Activation(\"relu\")(x)\n\n    if pool == True:\n        p = MaxPool2D((2, 2))(x)\n        return x, p\n    else:\n        return x\n\n'''build_unet it is used to create the U-net architecture.'''\n# function to build U-net\ndef build_unet(shape, num_classes):\n    inputs = Input(shape)\n\n    \"\"\" Encoder \"\"\"\n    x1, p1 = conv_block(inputs, 16, pool=True)\n    x2, p2 = conv_block(p1, 32, pool=True)\n    x3, p3 = conv_block(p2, 48, pool=True)\n    x4, p4 = conv_block(p3, 64, pool=True)\n    x5, p5 = conv_block(p3, 64, pool=True)\n    x6, p6 = conv_block(p3, 64, pool=True)\n\n    \"\"\" Bridge \"\"\"\n    b1 = conv_block(p4, 128, pool=False)\n\n    \"\"\" Decoder \"\"\"\n    u1 = UpSampling2D((2, 2), interpolation=\"bilinear\")(b1)\n    c1 = Concatenate()([u1, x4])\n    x5 = conv_block(c1, 64, pool=False)\n\n    u2 = UpSampling2D((2, 2), interpolation=\"bilinear\")(x5)\n    c2 = Concatenate()([u2, x3])\n    x6 = conv_block(c2, 48, pool=False)\n\n    u3 = UpSampling2D((2, 2), interpolation=\"bilinear\")(x6)\n    c3 = Concatenate()([u3, x2])\n    x7 = conv_block(c3, 32, pool=False)\n\n    u4 = UpSampling2D((2, 2), interpolation=\"bilinear\")(x7)\n    c4 = Concatenate()([u4, x1])\n    x8 = conv_block(c4, 16, pool=False)\n\n    \"\"\" Output layer \"\"\"\n    output = Conv2D(num_classes, 1, padding=\"same\", activation=\"softmax\")(x8)\n\n    return Model(inputs, output)","metadata":{"id":"tYCyf8smQXga","execution":{"iopub.status.busy":"2022-02-17T17:40:32.179169Z","iopub.execute_input":"2022-02-17T17:40:32.179414Z","iopub.status.idle":"2022-02-17T17:40:32.194841Z","shell.execute_reply.started":"2022-02-17T17:40:32.179384Z","shell.execute_reply":"2022-02-17T17:40:32.194113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# calling build_unet function\nimport segmentation_models as sm \n\nBACKBONE = 'efficientnetb7'\ninput_shape = (256, 256, 3)\nn_classes = 4\nactivation = 'softmax'\n\nmodel = sm.Unet(backbone_name = BACKBONE, \n                input_shape = input_shape, \n                classes = n_classes, \n                activation = activation,\n                encoder_weights = 'imagenet')\n\nmodel.summary()","metadata":{"id":"65hPnreJQXgb","execution":{"iopub.status.busy":"2022-02-17T17:50:42.863353Z","iopub.execute_input":"2022-02-17T17:50:42.863643Z","iopub.status.idle":"2022-02-17T17:52:02.962829Z","shell.execute_reply.started":"2022-02-17T17:50:42.863599Z","shell.execute_reply":"2022-02-17T17:52:02.962142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load model and compile","metadata":{"id":"bMgeqmX2QXgc"}},{"cell_type":"code","source":"lr = 1e-4\nbatch_size = 16\nepochs = 8\n\n# metrics for result validation\nmetrics = [sm.metrics.IOUScore(threshold=0.5), sm.metrics.FScore(threshold=0.5)]\n\n# compiling the model\nmodel.compile(loss = 'categorical_crossentropy', \n              optimizer = tf.keras.optimizers.Adam(lr), \n              metrics = metrics)\n\ntrain_steps = len(X_train)//batch_size\nvalid_steps = len(X_test)//batch_size\n","metadata":{"execution":{"iopub.status.busy":"2022-02-17T18:28:19.60108Z","iopub.execute_input":"2022-02-17T18:28:19.601347Z","iopub.status.idle":"2022-02-17T18:28:19.678724Z","shell.execute_reply.started":"2022-02-17T18:28:19.601314Z","shell.execute_reply":"2022-02-17T18:28:19.678035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# importing libraries\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping, TensorBoard\nfrom segmentation_models.metrics import iou_score\nimport datetime, os\n\n\"\"\" Hyperparameters \"\"\"\nimg_shape = (256, 256, 3)\nnum_classes = 4\nlr = 1e-4\nbatch_size = 16\nepochs = 8\n\n\"\"\" Model \"\"\"\nmodel = build_unet(img_shape, num_classes)\nmodel.compile(loss=\"categorical_crossentropy\", \n              optimizer=tf.keras.optimizers.Adam(lr), \n              metrics=[iou_score])\n\n\ntrain_steps = len(X_train)//batch_size\nvalid_steps = len(X_test)//batch_size\n\n\ncallbacks = [\n        tf.keras.callbacks.ModelCheckpoint(filepath=f'models/lunarModel_{current_datetime}.h5',\n                        monitor='val_iou_score', verbose=0, \n                        mode='max', save_best_model=True),\n             \n        tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_iou_score\", mode='max', patience=4,\n                          factor=0.1, verbose=0, min_lr=1e-6),\n             \n        tf.keras.callbacks.EarlyStopping(monitor=\"val_iou_score\", patience=5, verbose=0, mode='max'),\n\n        tf.keras.callbacks.TensorBoard(f'models/logs_{current_datetime}')\n    ]","metadata":{"id":"z91qV2ZwQXgc","execution":{"iopub.status.busy":"2022-02-17T15:41:28.899732Z","iopub.execute_input":"2022-02-17T15:41:28.902774Z","iopub.status.idle":"2022-02-17T15:41:29.445331Z","shell.execute_reply.started":"2022-02-17T15:41:28.902712Z","shell.execute_reply":"2022-02-17T15:41:29.444318Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train model","metadata":{"id":"SBhRPBKPQXgc"}},{"cell_type":"code","source":"'''model.fit is used to train the model'''\nmodel_history = model.fit(train_dataset,\n        steps_per_epoch=train_steps,\n        validation_data=valid_dataset,\n        validation_steps=valid_steps,\n        epochs=epochs,\n    )","metadata":{"id":"4lJgBNVwQXgd","execution":{"iopub.status.busy":"2022-02-17T18:28:33.924198Z","iopub.execute_input":"2022-02-17T18:28:33.925044Z"},"trusted":true},"execution_count":null,"outputs":[]}]}